---
layout: post
title:  "Some Thoughts on Newcomb Paradox"
---

I recently reread Robert Nozick's articles on the [Newcomb paradox](https://en.wikipedia.org/wiki/Newcomb%27s_paradox) in his book Socratic Puzzles. The paradox assumes there exists some being X that is able to predict your future decisions to incredibly high accuracy, and in front of you are two boxes A & B. Box A contains $1000 dollars and box B contains nothing if X predicts that you will take both boxes, or $1 million if X predicts that you will only take Box B. You are offered the choice to either 1) take both boxes or 2) take only box B. The prediction is made and the content of box B is determined ahead of time before you make your choice.

Option 2 obviously has a much higher expected return. However, regardless of the content of box B, taking box A after you have taken box B will always lead to a immediate positive gain of $1000. This seems to suggest you should be taking both boxes, thus creating a paradox.

To me it seems that the root of the confusion is in the ambiguity of the action space. Let's say I've chosen to take only box B and found that indeed there is a $1M inside. What's to stop me from spending all that cash and, say a year later, going back to where box A is and take the additional $1000? There seems to be a grey area in between the 2 choices that allows one to "morph" or "transition" from taking only one box to taking both.

To close this loose-end, let's introduce an additional control to the original scenario. Suppose instead of taking the boxes directly, the two boxes are locked inside a vending-machine-like contraption with two buttons. Button 1 will cause both boxes to drop for you to collect and button 2 will only drop box B. After either button is pressed whatever left inside will be incinerated immediately.

Now, under the assumptions of the paradox, pressing button 1 guarantees a payout of $1000 and pressing button 2 (almost) guarantees a payout of $1M. I don't see why anyone would press button 1 in this case, unless they are extremely risk-averse. The paradox then seems to be an argument against the generality of the dominance principle esp when the probabilistic structure is highly relevant. The notion that you should treat extremely improbable events on an equal footing when applying the dominance principle is baffling. By that token all of our daily decisions need to include possibilities like getting hit and killed by a meteor (negative infinite payout) and thus everyone should stay inside an nuclear bunker and never go out.

A further modification can be made such that the accuracy of X's prediction is no longer close to 100% but e.g. only 70%. In that case essentailly X can be replaced by a perfectly accurate predictor plus a coin toss. The scenario then becomes a gamble on the result of the coin toss and the choice you make is simply a reflection on how risk-seeking (how much of a gambler) you are.
